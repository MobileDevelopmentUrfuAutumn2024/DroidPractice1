<resources>
    <string name="app_name">DroidPractice1</string>
    <string name="article_title">Статья</string>
    <string name="article_header">Архитектура современных приложений на основе LLM</string>
    <string name="article_annotation">В этом посте мы рассмотрим пять наиболее важных этапов, который нужно пройти при разработке собственного приложения на основе LLM, формирующиеся общепринятые подходе к разработке таких приложений и предметные области, на которые стоит обратить внимание.</string>
    <string name="article_section1_subtitle">Пять шагов по созданию приложения с LLM</string>
    <string name="article_section1_body">Разработка приложения с LLM или любой другой моделью Машинного Обучения отличается от разработки приложения без них по ряду фундаментальных свойств. Например, вместо компиляции исходного кода в бинарный код, выполняющий последовательности команд, разработчикам приходится управлять наборами данных, эмбеддингов и параметрами моделей, чтобы получить согласованный результат. Кроме того, выход LLM имеет вероятностный характер — эти модели не выдают один и тот же предсказуемый результат.</string>

    <string name="article_main_text">Лицензия. Если вы рассчитываете продавать ваше приложение, вам нужно использовать модель, API которой допускает коммерческое использование. Для начала, вот список LLM с открытым кодом, лицензии которых допускают коммерческое использование. \n

        Размер модели. Размер LLM может изменяется в пределах от 7 до 175 миллиардов параметров. Некоторые, вроде Ada, могут быть еще меньше и иметь 350 миллионов параметров. Но большинство LLM (на момент написания этого поста) имеют от 7 до 13 миллиардов параметров.</string>
    <string name="article_additional_info_button_text">Читать далее</string>
    <string name="article_additional_info">Дообучение LLM
    При обучении LLM вы формируете модель общего назначения. Когда вы дообучаете модель, вы адаптируете её к конкретным задачам, вроде генерации текста на заданную тему или в конкретном стиле. Раздел поста ниже целиком посвящён этому вопросу. Для адаптации модели под ваши потребности, вы можете использовать in‑context learning, reinforcement learning from human feedback (RLHF) или fine‑tuning.

    In‑context learning, также известный как prompt engineering, это подход, при использовании которого вы даёте модели конкретные инструкции или примеры во время генерации ответа и просите модель определить что вы хотите, и сгенерировать подходящий по контексту ответ. In‑context learning можно выполнять разными способами, например, предъявляя примеры, перефразируя свои вопросы или явным образом добавляя инструкции о том, чего вы хотите.

    RLHF вводит понятие награждающей модели для предобученной LLM. Награждающая модель учится предсказывать, понравится ли пользователю ответ предобученной LLM. Обе модели взаимодействуют между собой, что заставляет LLM изменять свой ответ в соответствии с предпочтениями пользователя. Преимущество RLHF в том, что этот подход является обучением без учителя, и, как следствие, позволяет расширить критерии того, что является допустимым ответом. Имея достаточно обратной связи, LLM может выучить, что, если пользователь примет ответ с вероятностью 80%, то этот ответ можно предложить. Хотите попробовать сами? Ознакомьтесь с этими ресурсами для RLHF, включающими исходный код.

        Fine‑tuning это подход, когда генерированные моделью ответы сравниваются с заранее известными или желаемым ответами. Например, вы знаете, что модель должна оценить утверждение вроде «Суп слишком солёный» как негативно окрашенное. Для оценки модели вы подаёте ей это утверждение и просите оценить его как позитивно или негативно окрашенное. Если модель помечает его как позитивно окрашенное, вы изменяете параметры модели и пытаетесь снова проверить, оценит ли модель его как негативно окрашенное. Fine‑tuning позволяет получить очень кастомизированную модель, демонстрирующие отличные результаты в некоторой конкретной задаче. Но он относится к методам обучения с учителем и требует больших трудозатрат на разметку данных. Другими словами, нужно чтобы каждый пример был проанализирован классифицирован верно. В итоге фактический ответ модели можно сравнить с известным и затем изменить веса модели соответствующим образом. Преимущества RLHF в том, что, как было отмечено выше, ему не требуется знать точный ответ заранее.</string>

    <string name="is_read_switch_text">Просмотрено:</string>
</resources>